{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae6003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1:import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "#suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ecc6265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction function ready\n"
     ]
    }
   ],
   "source": [
    "#2:extracting audio features MFCCs, chroma, spectral features, ZCR, RMSE\n",
    "def extract_features(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None) #load audio file\n",
    "        \n",
    "        #extracted features\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13) \n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        spec_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        spec_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        \n",
    "        #store features mean and std\n",
    "        features = {}\n",
    "        for i in range(13):\n",
    "            features[f'mfcc_mean_{i+1}'] = np.mean(mfccs[i])\n",
    "            features[f'mfcc_std_{i+1}'] = np.std(mfccs[i])\n",
    "        \n",
    "        #update features\n",
    "        features.update({\n",
    "            'chroma_mean': np.mean(chroma), 'chroma_std': np.std(chroma),\n",
    "            'spec_centroid_mean': np.mean(spec_centroid), 'spec_centroid_std': np.std(spec_centroid),\n",
    "            'spec_bandwidth_mean': np.mean(spec_bandwidth), 'spec_bandwidth_std': np.std(spec_bandwidth),\n",
    "            'spec_rolloff_mean': np.mean(spec_rolloff), 'spec_rolloff_std': np.std(spec_rolloff),\n",
    "            'zcr_mean': np.mean(zcr), 'zcr_std': np.std(zcr),\n",
    "            'rmse_mean': np.mean(rmse), 'rmse_std': np.std(rmse)\n",
    "        })\n",
    "        return features\n",
    "   \n",
    "    #error handling\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {file_path}\")\n",
    "        return None\n",
    "\n",
    "print(\"Feature extraction function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89442afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio files...\n",
      " Processed 100 files...\n",
      " Processed 200 files...\n",
      " Processed 300 files...\n",
      " Processed 400 files...\n",
      " Processed 500 files...\n",
      " Processed 600 files...\n",
      " Processed 700 files...\n",
      " Processed 800 files...\n",
      " Processed 900 files...\n",
      " Processed 1000 files...\n",
      " Processed 1100 files...\n",
      " Processed 1200 files...\n",
      " Processed 1300 files...\n",
      " Processed 1400 files...\n",
      " Processed 1500 files...\n",
      " Processed 1600 files...\n",
      " Processed 1700 files...\n",
      " Processed 1800 files...\n",
      " Processed 1900 files...\n",
      " Processed 2000 files...\n",
      " Processed 2100 files...\n",
      " Processed 2200 files...\n",
      " Processed 2300 files...\n",
      " Processed 2400 files...\n",
      " Processed 2500 files...\n",
      " Processed 2600 files...\n",
      " Processed 2700 files...\n",
      " Processed 2800 files...\n",
      " Processed 2900 files...\n",
      " Processed 3000 files...\n",
      " Processed 3100 files...\n",
      " Processed 3200 files...\n",
      " Processed 3300 files...\n",
      " Processed 3400 files...\n",
      " Processed 3500 files...\n",
      " Processed 3600 files...\n",
      " Processed 3700 files...\n",
      " Processed 3800 files...\n",
      " Processed 3900 files...\n",
      " Processed 4000 files...\n",
      " Processed 4100 files...\n",
      "\n",
      "Dataset created with,  4170 samples, 38 features\n"
     ]
    }
   ],
   "source": [
    "#3:loading data and building dataframe\n",
    "\n",
    "data = []\n",
    "base_path = r\"C:\\Users\\siona\\Desktop\\Data\\Info_4000\\Valve\"  # Change to your data folder\n",
    "\n",
    "\n",
    "print(\"Loading audio files...\")\n",
    "for valve_id in os.listdir(base_path):\n",
    "    valve_path = os.path.join(base_path, valve_id)\n",
    "    if not os.path.isdir(valve_path):\n",
    "        continue\n",
    "    \n",
    "    #handles nested structure: Valve/id_00/id_00/abnormal\n",
    "    inner_valve_path = os.path.join(valve_path, valve_id)\n",
    "    if os.path.isdir(inner_valve_path):\n",
    "        valve_path = inner_valve_path  #use the nested folder\n",
    "    \n",
    "    #extract features\n",
    "    for condition in [\"normal\", \"abnormal\"]:\n",
    "        condition_path = os.path.join(valve_path, condition)\n",
    "        if not os.path.isdir(condition_path):\n",
    "            continue\n",
    "        \n",
    "        #handles nested structure\n",
    "        for file in os.listdir(condition_path):\n",
    "            if file.endswith(\".wav\"): #only wav files\n",
    "                file_path = os.path.join(condition_path, file) #full file path\n",
    "                features = extract_features(file_path) #extract features\n",
    "                if features:\n",
    "                    features[\"label\"] = 0 if condition == \"normal\" else 1 \n",
    "                    features[\"valve_id\"] = valve_id \n",
    "                    data.append(features) #store features\n",
    "                    if len(data) % 100 == 0:\n",
    "                        print(f\" Processed {len(data)} files...\")#print progress\n",
    "\n",
    "#create dataframe\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"\\nDataset created with,  {df.shape[0]} samples, {df.shape[1]-2} features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07dddcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Dataset Overview:\n",
      "Shape: (4170, 40)\n",
      "\n",
      "the label distribution:\n",
      "label\n",
      "0    3691\n",
      "1     479\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Printing first 5 rows: \n",
      "   mfcc_mean_1  mfcc_std_1  mfcc_mean_2  mfcc_std_2  mfcc_mean_3  mfcc_std_3  \\\n",
      "0  -453.536346   62.326683   111.516434   36.946873     9.088650   12.933658   \n",
      "1  -407.746124   43.768436    93.851753   27.782482    -3.282425   10.550710   \n",
      "2  -435.306610   51.851673    98.593742   31.520517     1.550137   10.447041   \n",
      "3  -430.467712   51.209702   113.662689   34.732361    -3.186110   12.423004   \n",
      "4  -473.426910   69.769539   124.112320   42.873428     9.627452   14.904742   \n",
      "\n",
      "   mfcc_mean_4  mfcc_std_4  mfcc_mean_5  mfcc_std_5  ...  spec_bandwidth_mean  \\\n",
      "0    17.291801    9.700444    12.015554    5.246408  ...          1725.775371   \n",
      "1    17.772728   11.152828    -1.624269    7.094705  ...          1835.443473   \n",
      "2    -1.708624    5.369768     4.929927    3.855741  ...          1883.026426   \n",
      "3    20.563763   11.926163     3.592756    6.686066  ...          1654.440884   \n",
      "4    13.995111    8.256240    12.587856    5.294329  ...          1605.053991   \n",
      "\n",
      "   spec_bandwidth_std  spec_rolloff_mean  spec_rolloff_std  zcr_mean  \\\n",
      "0          352.408999        3047.474042       1545.831378  0.079894   \n",
      "1          257.386505        3912.390176       1055.578444  0.124808   \n",
      "2          246.237352        3634.235224       1273.086297  0.126131   \n",
      "3          350.414886        3177.540935       1382.614594  0.094620   \n",
      "4          427.617319        2662.065695       1757.975596  0.070600   \n",
      "\n",
      "    zcr_std  rmse_mean  rmse_std  label  valve_id  \n",
      "0  0.054647   0.003014  0.001330      0     id_00  \n",
      "1  0.049083   0.002967  0.001332      0     id_00  \n",
      "2  0.053025   0.002746  0.001376      0     id_00  \n",
      "3  0.052677   0.003000  0.001347      0     id_00  \n",
      "4  0.054329   0.002976  0.001399      0     id_00  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "#4: data overview\n",
    "print(\"\\n  Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nthe label distribution:\\n{df['label'].value_counts()}\")\n",
    "print(f\"\\nPrinting first 5 rows: \")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9716d28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained\n"
     ]
    }
   ],
   "source": [
    "#5: model training\n",
    "# prep data\n",
    "X = df.drop(['label', 'valve_id'], axis=1)\n",
    "y = df['label']\n",
    "\n",
    "#split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#train model\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42) #create model with 200 trees\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d604f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 96.52%\n",
      "Meets 90%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[738   0]\n",
      " [ 29  67]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.96      1.00      0.98       738\n",
      "    Abnormal       1.00      0.70      0.82        96\n",
      "\n",
      "    accuracy                           0.97       834\n",
      "   macro avg       0.98      0.85      0.90       834\n",
      "weighted avg       0.97      0.97      0.96       834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6: model eval\n",
    "y_pred = model.predict(X_test) #predict\n",
    "accuracy = accuracy_score(y_test, y_pred) #calc accuracy\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy*100:.2f}%\")\n",
    "if accuracy >= 0.90:\n",
    "    print(\"Meets 90%\") #meets requirement\n",
    "else:\n",
    "    print(\"Below 90%\") # might need tuning\n",
    "\n",
    "#confusion matrix and the classification report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "print(f\"\\n{classification_report(y_test, y_pred, target_names=['Normal', 'Abnormal'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e3c602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions on new data:\n",
      "  Valve1_000NB.wav: Normal\n",
      "  Valve2_000AB.wav: Abnormal\n",
      "\n",
      "Summary:                File Prediction\n",
      "0  Valve1_000NB.wav     Normal\n",
      "1  Valve2_000AB.wav   Abnormal\n"
     ]
    }
   ],
   "source": [
    "#7:predict on new data\n",
    "new_data_folder = r\"C:\\Users\\siona\\Desktop\\Projects\\INFO_4000\\Week 09\\Exercise MP2\\Attempt\\Part2_MP2\\Valve_Data_for_Prediction\"  # Change to your test folder\n",
    "\n",
    "#check if folder exists\n",
    "if os.path.exists(new_data_folder):\n",
    "    print(\"\\nPredictions on new data:\")\n",
    "    results = []\n",
    "    \n",
    "    #predict\n",
    "    for file in os.listdir(new_data_folder):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(new_data_folder, file)\n",
    "            features = extract_features(file_path)\n",
    "            if features: #check if features were extracted\n",
    "                new_df = pd.DataFrame([features])\n",
    "                new_scaled = scaler.transform(new_df)\n",
    "                prediction = model.predict(new_scaled)[0] #predict\n",
    "                label = \"Normal\" if prediction == 0 else \"Abnormal\" #label\n",
    "                results.append({'File': file, 'Prediction': label}) #store results\n",
    "                print(f\"  {file}: {label}\") # print\n",
    "    \n",
    "    #print summary\n",
    "    if results:\n",
    "        print(f\"\\nSummary: {pd.DataFrame(results)}\")\n",
    "else:\n",
    "    print(f\"\\n'{new_data_folder}' folder not found\") #if folder is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f82d1512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model and scaler saved\n"
     ]
    }
   ],
   "source": [
    "#8: save model\n",
    "joblib.dump(model, \"valve_classifier.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"\\nModel and scaler saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2340d66c",
   "metadata": {},
   "source": [
    "Assignment asks for the questions to be put into a cell, does it mean code or markdown? I did markdown.\n",
    "\n",
    "1. While you built this application in the classical ML way using tabular data, what is the other\n",
    "way you could have built this application where Deep Learning can be used? Explain the\n",
    "basic concept of that method and explain how it works.\n",
    "\n",
    "    An alternative would be to use a CNN on the mel-spectograms which are the 2D images: time x frequency x amplitude, instead of manually extracting features, converts each audio clip ino mel-spectograms image.\n",
    "\n",
    "    So converts audio to mel-spectrogram, then feeds into CNN layers (Conv2D layers, Pooling, Flatten, Dense, Output)\n",
    "    so as an example:\n",
    "    Audio to Mel-spectrogram to Conv2D to MaxPool to Conv2D to MaxPool to Flatten to Dense to Output (Normal/Abnormal)\n",
    "\n",
    "    This is good since it works well with larger datasets and can find patterns taht a classical ML might miss.\n",
    "\n",
    "\n",
    "2. Explain how one would have to preprocess the data to adopt the above deep learning\n",
    "method and how that can be implemented?\n",
    "\n",
    "   The first step would be to load the audio with librosa adn resample to a fixed rate. Create a fixed length so all the audio is a fixed lenght (ex. 3 seconds). Then create a mel-spectrogram \n",
    "   in our case:\n",
    "\n",
    "   mel = librosa.feature.melspectrogram(y, sr=sr, n_mels=128, n_fft=2048, hop_length=512)\n",
    "   mel_db = librosa.power_to_db(mel)\n",
    "\n",
    "   Then Normalize scale pixels for training and convergence [0,1]. And if needed you can also add data augmentation like time stretching or noise addition etc. \n",
    "   After all this the audio should be clean and standardized 2D input ready for a CNN\n",
    "\n",
    "\n",
    "\n",
    "3. In completing this application what were the challenges and what were three takeaways\n",
    "that you would consider significant in understanding audio analytics?\n",
    "\n",
    "   The challenges faced were quite a bit but excluding from the assignment, one was my laptop itself acting up and crashing every so often, making the problem of extracting features which takes time due to many files more difficult than it already was. Others include managing nested folders and inconsistent audio lentghs, choosing the best feature, and reaching 90% accuracy through tuning.\n",
    "\n",
    "   The main take aways were that:\n",
    "   \n",
    "   a. Audio contians more than one variable including time,frequency, amplitude, etc. Making it important to use MFCCs for tone and texture, Spectral for Frequency distribution, ZCR/RMSE for Noisiness and energy. Combining all helps improve accuracy.\n",
    "\n",
    "   b. Preprocessing matters becasue scaling avoids bias from large-value features, and using mean + std captures both behavior and variation.\n",
    "\n",
    "   c. Domain knowledge helps, knowing how valves sound helps interpret MFCCs and spectra. Like Worn bearing might make a higher freq. noise, or a belt on a machine squaking giving an altered sound. \n",
    "   So a classical ML works but needs features which require expertise to create, while DL learns features automatically but needs more data and is less interpretable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
