{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3603fb4c-2f20-426b-9ce1-3084739b6b8e",
   "metadata": {},
   "source": [
    "#### HF Tokenizers ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e67e60-86e7-4b14-9187-3018ecac9ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raoji\\miniconda3\\envs\\py312_torch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ad8bb-7621-4af1-8859-d48e5c23209d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Encoding #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5221c1c-f655-40a0-9d02-f804ccbb15bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Using', 'a', 'Trans', '##former', 'network', 'is', 'simple']\n"
     ]
    }
   ],
   "source": [
    "# This tokenizer is a subword tokenizer: it splits the words until it obtains tokens that can be represented by its vocabulary. \n",
    "# Thatâ€™s the case here with transformer, which is split into two tokens: transform and ##er.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "sequence = \"Using a Transformer network is simple\"\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4657453e-1432-43a4-b562-04894e1047fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These outputs, once converted to the appropriate framework tensor, can then be used as inputs to a model:\n",
      "[7993, 170, 13809, 23763, 2443, 1110, 3014]\n"
     ]
    }
   ],
   "source": [
    "# The conversion to input IDs is handled by the convert_tokens_to_ids() tokenizer method:\n",
    "\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(f\"These outputs, once converted to the appropriate framework tensor, can then be used as inputs to a model:\\n{ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af786e4-471e-441c-ae2c-c7437040815e",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Decoding #####\n",
    "\n",
    "Decoding is going the other way around: from vocabulary indices, we want to get a string. \n",
    "\n",
    "This can be done with the decode() method as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dac0b46-6041-48f6-9852-4bef206076cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a transformer network is simple\n"
     ]
    }
   ],
   "source": [
    "decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])\n",
    "print(decoded_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763d7ffe-3d24-433d-a406-403d9a6d1df5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Note that the decode method not only converts the indices back to tokens, but also groups together the tokens that were part of the same words to produce a readable sentence. This behavior will be extremely useful when we use models that predict new text (either text generated from a prompt, or for sequence-to-sequence problems like translation or summarization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636645dc-4602-4c60-9a6c-6356d53b8664",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
