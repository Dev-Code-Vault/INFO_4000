{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d09376d-712e-4eec-b4a4-09e80815cc61",
   "metadata": {},
   "source": [
    "#### 1. Converting audio data into a structured data form allows for easier analysis and manipulation. Here's a step-by-step guide on how to convert audio data into structured data using Python: ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ee5e39-46a6-4df3-9641-e8515eb83f5b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Load the Audio Data\n",
    "# You can use the `librosa` library to load audio files and extract various features from them.\n",
    "\n",
    "# pip install librosa\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1177cc49-3d47-4f74-8176-b4658d7b7bf5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the audio file\n",
    "y, sr = librosa.load(\"Jazzy_Piano_AI_Genrated.mp3\")\n",
    "\n",
    "# `y` contains the audio time series, and `sr` is the sampling rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09961e2-f52f-4486-8b6d-1aea0c3ecba3",
   "metadata": {},
   "source": [
    "#### 2. Extract Basic Features ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28d421-f72d-4809-9225-a129733a22c6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Temporal Features:\n",
    "# Zero Crossing Rate: Rate of sign-changes along a signal.\n",
    "\n",
    "zcr = librosa.feature.zero_crossing_rate(y)\n",
    "print(len(zcr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca54bed-2926-4537-8d7c-5a025ffb5efb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Spectral Features:\n",
    "#Spectral Centroid: Indicates where the center of mass of the spectrum is located.\n",
    "spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "\n",
    "# Spectral Bandwidth: Width of the spectrum.\n",
    "spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "print(f\"Spectral Centroid: {spectral_centroid[0][:5]}\\n\\nSpectral Bandwitdth: {spectral_bandwidth[0][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929c5312-b320-4169-bb0e-1a5e0b72d531",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rhythmic Features:\n",
    "# Tempo and Beat Frames: \n",
    "tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "print(f\"Tempo: {tempo}\\nBeat Frames: {beat_frames}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d94fa-908a-4ad1-8584-aa2830a23f3c",
   "metadata": {},
   "source": [
    "#### 3. Extract Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ba9fe8-fedf-447b-98c5-e85ddc150fec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mel-Frequency Cepstral Coefficients (MFCC):\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "print(f\"Mel frequencies: {len(mfccs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae11b50-703e-444b-9b0c-44c73dcc7f1f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chroma Feature:\n",
    "# Represents the energy distribution across the 12 different pitch classes.\n",
    "chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "print(f\"Chroma - Energy Distribution:\\n{chroma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a0490-4ca3-48ed-818d-6566483833e3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tonnetz:\n",
    "# Captures harmonic relations in the audio.\n",
    "tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "print(f\"Numner of harmonic relations: {len(tonnetz)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add34f24-c938-4810-bdb7-62f420bf405f",
   "metadata": {},
   "source": [
    "#### 4. Structured Data Representation ####\n",
    "\n",
    "Once the features are extracted, they can be represented in a structured form such as a DataFrame using `pandas`.\n",
    "\n",
    "This structured data form makes it easier to analyze the extracted audio features, use them in machine learning models, or store them in databases for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34458326-f2a1-41a3-8ca4-7b2180b8d174",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary of features\n",
    "data = {\n",
    "    'Zero Crossing Rate': zcr.mean(),\n",
    "    'Spectral Centroid': spectral_centroid.mean(),\n",
    "    'Spectral Bandwidth': spectral_bandwidth.mean(),\n",
    "    'Tempo': tempo,\n",
    "    'MFCC1': mfccs[0].mean(),\n",
    "    'MFCC2': mfccs[1].mean(),\n",
    "    #... add other MFCCs or features as needed\n",
    "    'Chroma1': chroma[0].mean(),\n",
    "    'Chroma2': chroma[1].mean(),\n",
    "    #... add other Chroma features as needed\n",
    "    'Tonnetz1': tonnetz[0].mean(),\n",
    "    'Tonnetz2': tonnetz[1].mean()\n",
    "    #... add other Tonnetz features as needed\n",
    "}\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df = pd.DataFrame([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4271528b-61e3-4761-83ce-4fe0c584e70f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe1f2cc-27da-49e5-8482-55fc8d9b6e16",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "torchgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
