{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed3416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Exercise 10 - Part 1: Autoencoder for Defect Detection\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# ============================================================\n",
    "# 1. Load and Prepare Image Data\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Loading Defect Detection Dataset...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def load_images_from_folder(folder_path, img_size=(64, 64)):\n",
    "    \"\"\"Load images from a folder and flatten them\"\"\"\n",
    "    images = []\n",
    "    for img_path in glob.glob(os.path.join(folder_path, '*.png')):\n",
    "        img = Image.open(img_path).convert('L')  # Grayscale\n",
    "        img = img.resize(img_size)\n",
    "        img_array = np.array(img) / 255.0  # Normalize to [0, 1]\n",
    "        images.append(img_array.flatten())\n",
    "    return np.array(images)\n",
    "\n",
    "# Load training data\n",
    "train_good = load_images_from_folder('defect/train/good')\n",
    "train_defective = load_images_from_folder('defect/train/defective')\n",
    "train_data = np.vstack([train_good, train_defective])\n",
    "\n",
    "print(f\"Training - Good images: {len(train_good)}\")\n",
    "print(f\"Training - Defective images: {len(train_defective)}\")\n",
    "print(f\"Total training images: {len(train_data)}\")\n",
    "print(f\"Image shape (flattened): {train_data.shape}\")\n",
    "\n",
    "# Load test data\n",
    "test_good = load_images_from_folder('defect/test/good')\n",
    "test_defective = load_images_from_folder('defect/test/defective')\n",
    "test_data = np.vstack([test_good, test_defective])\n",
    "\n",
    "# Create labels for test data (0 = good, 1 = defective)\n",
    "test_labels = np.array([0]*len(test_good) + [1]*len(test_defective))\n",
    "\n",
    "print(f\"\\nTest - Good images: {len(test_good)}\")\n",
    "print(f\"Test - Defective images: {len(test_defective)}\")\n",
    "print(f\"Total test images: {len(test_data)}\")\n",
    "\n",
    "# Visualize some samples\n",
    "print(\"\\nVisualizing sample images...\")\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "img_size = int(np.sqrt(train_data.shape[1]))\n",
    "\n",
    "for i in range(5):\n",
    "    # Good image\n",
    "    axes[0, i].imshow(train_good[i].reshape(img_size, img_size), cmap='gray')\n",
    "    axes[0, i].set_title('Good')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Defective image\n",
    "    axes[1, i].imshow(train_defective[i].reshape(img_size, img_size), cmap='gray')\n",
    "    axes[1, i].set_title('Defective')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Training Images', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 2. Define AutoEncoder\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Building AutoEncoder Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "input_dim = train_data.shape[1]  # Flattened image size\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim=32):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Initialize model\n",
    "model = AutoEncoder(input_dim=input_dim, encoding_dim=32)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "print(f\"Encoding dimension: 32\")\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# ============================================================\n",
    "# 3. Train AutoEncoder (on GOOD images only)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training AutoEncoder on GOOD images only...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_good = torch.FloatTensor(train_good)\n",
    "\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_good)\n",
    "    loss = criterion(outputs, X_train_good)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_losses.append(loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}')\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('MSE Loss', fontsize=12)\n",
    "plt.title('AutoEncoder Training Loss', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 4. Detect Anomalies in Test Data\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Detecting Anomalies in Test Data...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Convert test data to tensor\n",
    "X_test = torch.FloatTensor(test_data)\n",
    "\n",
    "# Get reconstructions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    reconstructions = model(X_test)\n",
    "    mse = torch.mean((X_test - reconstructions) ** 2, dim=1)\n",
    "\n",
    "reconstruction_errors = mse.numpy()\n",
    "\n",
    "# Set threshold at 95th percentile\n",
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "predicted_anomalies = reconstruction_errors > threshold\n",
    "\n",
    "print(f\"\\nReconstruction Error Statistics:\")\n",
    "print(f\"  Mean: {reconstruction_errors.mean():.6f}\")\n",
    "print(f\"  Std: {reconstruction_errors.std():.6f}\")\n",
    "print(f\"  Min: {reconstruction_errors.min():.6f}\")\n",
    "print(f\"  Max: {reconstruction_errors.max():.6f}\")\n",
    "print(f\"  Threshold (95th percentile): {threshold:.6f}\")\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Total test samples: {len(test_data)}\")\n",
    "print(f\"  Predicted anomalies: {np.sum(predicted_anomalies)}\")\n",
    "print(f\"  Actual defective: {np.sum(test_labels == 1)}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. Visualize Results\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Creating Visualizations...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Plot reconstruction error\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(reconstruction_errors, 'o-', markersize=4, alpha=0.6, label='Reconstruction Error')\n",
    "plt.axhline(threshold, color='r', linestyle='--', linewidth=2, \n",
    "            label=f'Threshold (95th percentile = {threshold:.6f})')\n",
    "plt.xlabel('Test Sample Index', fontsize=12)\n",
    "plt.ylabel('MSE (Reconstruction Error)', fontsize=12)\n",
    "plt.title('AutoEncoder: Anomaly Detection Results', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize original vs reconstructed images\n",
    "print(\"\\nVisualizing Original vs Reconstructed Images...\")\n",
    "\n",
    "fig, axes = plt.subplots(4, 6, figsize=(15, 10))\n",
    "\n",
    "# Show good images (low error)\n",
    "good_indices = np.where(test_labels == 0)[0][:3]\n",
    "for i, idx in enumerate(good_indices):\n",
    "    # Original\n",
    "    axes[0, i*2].imshow(test_data[idx].reshape(img_size, img_size), cmap='gray')\n",
    "    axes[0, i*2].set_title(f'Good Original\\nError: {reconstruction_errors[idx]:.4f}', fontsize=9)\n",
    "    axes[0, i*2].axis('off')\n",
    "    # Reconstructed\n",
    "    axes[0, i*2+1].imshow(reconstructions[idx].numpy().reshape(img_size, img_size), cmap='gray')\n",
    "    axes[0, i*2+1].set_title('Reconstructed', fontsize=9)\n",
    "    axes[0, i*2+1].axis('off')\n",
    "\n",
    "# Show defective images (should have high error)\n",
    "defect_indices = np.where(test_labels == 1)[0][:3]\n",
    "for i, idx in enumerate(defect_indices):\n",
    "    # Original\n",
    "    axes[1, i*2].imshow(test_data[idx].reshape(img_size, img_size), cmap='gray')\n",
    "    axes[1, i*2].set_title(f'Defective Original\\nError: {reconstruction_errors[idx]:.4f}', fontsize=9)\n",
    "    axes[1, i*2].axis('off')\n",
    "    # Reconstructed\n",
    "    axes[1, i*2+1].imshow(reconstructions[idx].numpy().reshape(img_size, img_size), cmap='gray')\n",
    "    axes[1, i*2+1].set_title('Reconstructed', fontsize=9)\n",
    "    axes[1, i*2+1].axis('off')\n",
    "\n",
    "# Show highest error samples (predicted anomalies)\n",
    "highest_error_idx = np.argsort(reconstruction_errors)[-3:][::-1]\n",
    "for i, idx in enumerate(highest_error_idx):\n",
    "    # Original\n",
    "    axes[2, i*2].imshow(test_data[idx].reshape(img_size, img_size), cmap='gray')\n",
    "    axes[2, i*2].set_title(f'Highest Error\\nError: {reconstruction_errors[idx]:.4f}', fontsize=9)\n",
    "    axes[2, i*2].axis('off')\n",
    "    # Reconstructed\n",
    "    axes[2, i*2+1].imshow(reconstructions[idx].numpy().reshape(img_size, img_size), cmap='gray')\n",
    "    axes[2, i*2+1].set_title('Reconstructed', fontsize=9)\n",
    "    axes[2, i*2+1].axis('off')\n",
    "\n",
    "# Show lowest error samples (normal)\n",
    "lowest_error_idx = np.argsort(reconstruction_errors)[:3]\n",
    "for i, idx in enumerate(lowest_error_idx):\n",
    "    # Original\n",
    "    axes[3, i*2].imshow(test_data[idx].reshape(img_size, img_size), cmap='gray')\n",
    "    axes[3, i*2].set_title(f'Lowest Error\\nError: {reconstruction_errors[idx]:.4f}', fontsize=9)\n",
    "    axes[3, i*2].axis('off')\n",
    "    # Reconstructed\n",
    "    axes[3, i*2+1].imshow(reconstructions[idx].numpy().reshape(img_size, img_size), cmap='gray')\n",
    "    axes[3, i*2+1].set_title('Reconstructed', fontsize=9)\n",
    "    axes[3, i*2+1].axis('off')\n",
    "\n",
    "plt.suptitle('AutoEncoder: Original vs Reconstructed Images', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AutoEncoder Defect Detection Complete!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
