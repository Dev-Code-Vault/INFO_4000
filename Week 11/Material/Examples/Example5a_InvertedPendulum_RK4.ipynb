{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4376343d-dcde-40a7-a95c-28737534be72",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "\n",
    "Inverted Pendulum — Digital Twin (DT) \n",
    "=====================================\n",
    "\n",
    "In this example we have\n",
    "-----------------------\n",
    "1) **Nonlinear plant** (rotary inverted pendulum with direct torque at the pivot).\n",
    "2) **PID controller** to swing-up and stabilize at the upright setpoint (θ* = π rad).\n",
    "3) **Digital Twin runner** that logs telemetry and compares truth vs twin.\n",
    "4) **PINN** (Physics-Informed Neural Network) that learns from telemetry by\n",
    "   minimizing the ODE residual **and** a small amount of data-fit loss; the PINN\n",
    "   estimates the damping b (and can be extended to estimate m if desired) and\n",
    "   reconstructs θ(t) from time alone + known input u(t).\n",
    "5) **Visualization**: time-series plots + a simple animation of the pendulum.\n",
    "\n",
    "System model\n",
    "------------\n",
    "We use a simple rotary-pendulum model with a torque input u at the hinge:\n",
    "\n",
    "$m l^2 θ¨ + b θ˙ + m g l sin(θ) = u$\n",
    "\n",
    "=> $θ¨ = [u - b θ˙ - m g l sin(θ)] / (m l^2)$\n",
    "\n",
    "State vector: x = [θ, θ̇]. \n",
    "\n",
    "Parameters: mass m, length l, viscous friction b, gravity g.\n",
    "\n",
    "We treat the rod as massless with a point mass m at distance l; feel free to\n",
    "swap in a more detailed inertia if teaching moment-of-inertia composition.\n",
    "\n",
    "Controller objective\n",
    "--------------------\n",
    "Setpoint θ* = π (upright). We define a wrapped angle error e = wrap_to_pi(θ* - θ)\n",
    "so the controller sees the shortest-direction error. The PID uses:\n",
    "  - anti-windup via clamping on integral term\n",
    "  - derivative-on-measurement (less noise-sensitive than derivative-on-error)\n",
    "  - torque saturation (|u| ≤ u_max)\n",
    "\n",
    "Digital Twin idea here\n",
    "----------------------\n",
    "The **truth plant** runs the actual ODE forward in time. The **twin** includes a\n",
    "PINN that, after we run a scenario, trains on the collected telemetry\n",
    "{t_i, θ_i, u_i}. The PINN learns θ(t) and a parameter b (can be extended to m)\n",
    "by minimizing the ODE residual and a tiny supervised fit loss.\n",
    "\n",
    "\n",
    "Key knobs to try in main()\n",
    "--------------------------\n",
    "- Change gains: Kp, Ki, Kd\n",
    "- Change parameters: m, l, b, g\n",
    "- Change torque saturation u_max\n",
    "- Toggle PINN training or shorten epochs for quick class demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab3a48",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ada649",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Needed for PINN part\n",
    "try:\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    TORCH_AVAILABLE = True\n",
    "except Exception:\n",
    "    TORCH_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81903aad-4b73-4a43-9c7b-6f5581efe81e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Keep path to pi open from both ends\n",
    "def wrap_to_pi(angle: float) -> float:\n",
    "    \"\"\"Wrap any angle (rad) into (-π, π].\"\"\"\n",
    "    a = (angle + math.pi) % (2 * math.pi) - math.pi\n",
    "    return a\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Plant (truth) — nonlinear ODE with RK4 integrator\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class PendulumParams:\n",
    "    m: float = 0.5     # kg\n",
    "    l: float = 0.5     # m\n",
    "    b: float = 0.05    # N·m·s (viscous friction)\n",
    "    g: float = 9.81    # m/s^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2fe8dd",
   "metadata": {},
   "source": [
    "#### Utilities and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90647e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class InvertedPendulumPlant:\n",
    "    def __init__(self, params: PendulumParams):\n",
    "        self.p = params\n",
    "        self.state = np.array([0.0, 0.0], dtype=float)  # [theta, theta_dot]\n",
    "\n",
    "    def reset(self, theta: float = 0.0, theta_dot: float = 0.0):\n",
    "        self.state = np.array([theta, theta_dot], dtype=float)\n",
    "        return self.state.copy()\n",
    "\n",
    "    def f(self, x: np.ndarray, u: float) -> np.ndarray:\n",
    "        theta, theta_dot = x\n",
    "        m, l, b, g = self.p.m, self.p.l, self.p.b, self.p.g\n",
    "        theta_ddot = (u - b * theta_dot - m * g * l * math.sin(theta)) / (m * l * l)\n",
    "        return np.array([theta_dot, theta_ddot])\n",
    "\n",
    "    def step(self, u: float, dt: float) -> np.ndarray:\n",
    "        \"\"\"One RK4 step.\"\"\"\n",
    "        x = self.state\n",
    "        k1 = self.f(x, u)\n",
    "        k2 = self.f(x + 0.5 * dt * k1, u)\n",
    "        k3 = self.f(x + 0.5 * dt * k2, u)\n",
    "        k4 = self.f(x + dt * k3, u)\n",
    "        x_next = x + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "        self.state = x_next\n",
    "        return x_next.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8275efae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# PID Controller\n",
    "# -----------------------------\n",
    "class PID:\n",
    "    def __init__(self, kp: float, ki: float, kd: float, u_max: float = 2.0, i_clamp: float = 1.0):\n",
    "        self.kp = kp\n",
    "        self.ki = ki\n",
    "        self.kd = kd\n",
    "        self.u_max = abs(u_max)\n",
    "        self.i_clamp = abs(i_clamp)\n",
    "        self.integral = 0.0\n",
    "        self.prev_meas = None  # derivative-on-measurement\n",
    "\n",
    "    def reset(self):\n",
    "        self.integral = 0.0\n",
    "        self.prev_meas = None\n",
    "\n",
    "    def __call__(self, setpoint: float, measurement: float, dt: float) -> float:\n",
    "        # wrapped angle error\n",
    "        e = wrap_to_pi(setpoint - measurement)\n",
    "\n",
    "        # integral with clamping (anti-windup)\n",
    "        self.integral += e * dt\n",
    "        self.integral = np.clip(self.integral, -self.i_clamp, self.i_clamp)\n",
    "\n",
    "        # derivative on measurement (less noise sensitive)\n",
    "        if self.prev_meas is None:\n",
    "            d_meas = 0.0\n",
    "        else:\n",
    "            d_meas = (measurement - self.prev_meas) / dt\n",
    "        self.prev_meas = measurement\n",
    "\n",
    "        u = self.kp * e + self.ki * self.integral - self.kd * d_meas\n",
    "        u = float(np.clip(u, -self.u_max, self.u_max))\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5cbc8f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Digital Twin Run\n",
    "# -----------------------------\n",
    "class DigitalTwin:\n",
    "    def __init__(self, plant: InvertedPendulumPlant, controller: PID, dt: float = 0.01):\n",
    "        self.plant = plant\n",
    "        self.ctrl = controller\n",
    "        self.dt = dt\n",
    "        self.log: Dict[str, List[float]] = {k: [] for k in [\n",
    "            't', 'theta', 'theta_dot', 'u', 'e', 'setpoint'\n",
    "        ]}\n",
    "\n",
    "    def run(self, T: float = 6.0, theta0: float = 0.0, theta_dot0: float = 0.0, setpoint: float = math.pi,\n",
    "            pre_kick: float | None = None, kick_duration: float = 0.2):\n",
    "        \"\"\"Run closed-loop sim for T seconds. Optionally apply an initial torque 'kick'.\"\"\"\n",
    "        self.plant.reset(theta0, theta_dot0)\n",
    "        self.ctrl.reset()\n",
    "        N = int(T / self.dt)\n",
    "\n",
    "        for k in range(N):\n",
    "            t = k * self.dt\n",
    "            theta, theta_dot = self.plant.state\n",
    "\n",
    "            # optional initial impulse/kick helps swing-up if gains are gentle\n",
    "            if pre_kick is not None and t < kick_duration:\n",
    "                u = float(np.clip(pre_kick, -self.ctrl.u_max, self.ctrl.u_max))\n",
    "            else:\n",
    "                u = self.ctrl(setpoint, theta, self.dt)\n",
    "\n",
    "            x_next = self.plant.step(u, self.dt)\n",
    "\n",
    "            # log data\n",
    "            e = wrap_to_pi(setpoint - theta)\n",
    "            self.log['t'].append(t)\n",
    "            self.log['theta'].append(theta)\n",
    "            self.log['theta_dot'].append(theta_dot)\n",
    "            self.log['u'].append(u)\n",
    "            self.log['e'].append(e)\n",
    "            self.log['setpoint'].append(setpoint)\n",
    "\n",
    "        return self.get_log()\n",
    "\n",
    "    def get_log(self) -> Dict[str, np.ndarray]:\n",
    "        return {k: np.asarray(v, dtype=float) for k, v in self.log.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ad7e1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# PINN — learns θ(t) and damping b from telemetry\n",
    "# -----------------------------\n",
    "from dataclasses import dataclass as _dataclass\n",
    "\n",
    "@_dataclass\n",
    "class PINNArtifact:\n",
    "    \"\"\"Serializable PINN snapshot to reuse without retraining.\"\"\"\n",
    "    hidden: int\n",
    "    state_dict: dict\n",
    "    t_min: float\n",
    "    t_max: float\n",
    "    b_hat: float\n",
    "\n",
    "    def build_model(self):\n",
    "        m = PINNStateOfTime(hidden=self.hidden)\n",
    "        m.load_state_dict(self.state_dict)\n",
    "        m.eval()\n",
    "        return m\n",
    "\n",
    "    def predict_theta(self, t_array: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Forward θ(t) with the frozen PINN; no gradients needed.\"\"\"\n",
    "        if not TORCH_AVAILABLE:\n",
    "            raise RuntimeError(\"PyTorch not available for PINN prediction.\")\n",
    "        with torch.no_grad():\n",
    "            t = torch.tensor(t_array, dtype=torch.float32).unsqueeze(1)\n",
    "            t_norm = (2.0 * (t - self.t_min) / (self.t_max - self.t_min + 1e-9)) - 1.0\n",
    "            model = self.build_model()\n",
    "            y = model(t_norm)\n",
    "            theta_hat = y[:, 0].cpu().numpy()\n",
    "        return theta_hat\n",
    "    \n",
    "class PINNStateOfTime(nn.Module):\n",
    "    \"\"\"Outputs θ(t) and ω(t)=θ̇(t). Learns damping b via softplus.\"\"\"\n",
    "    def __init__(self, hidden: int = 64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, hidden), nn.Tanh(),\n",
    "            nn.Linear(hidden, hidden), nn.Tanh(),\n",
    "            nn.Linear(hidden, hidden), nn.Tanh(),\n",
    "            nn.Linear(hidden, 2)  # -> [theta, omega]\n",
    "        )\n",
    "        self.b_raw = nn.Parameter(torch.tensor(0.05))\n",
    "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(t)\n",
    "    @property\n",
    "    def b_hat(self) -> torch.Tensor:\n",
    "        return torch.nn.functional.softplus(self.b_raw)\n",
    "\n",
    "\n",
    "def train_pinn(log: Dict[str, np.ndarray], m: float, l: float, g: float,\n",
    "               epochs: int = 2500, lr: float = 1e-3, data_weight: float = 5e-2,\n",
    "               b_prior: float | None = None, b_prior_w: float = 2e-3,\n",
    "               warmup_epochs: int = 300,\n",
    "               device: str = 'cpu'):\n",
    "    \"\"\"Train a PINN to match θ(t) and estimate b given known (u(t), m, l, g).\n",
    "    The loss = MSE(residual) + data_weight * MSE(data_fit).\n",
    "    \"\"\"\n",
    "    if not TORCH_AVAILABLE:\n",
    "        print(\"PyTorch not available — skipping PINN training.\")\n",
    "        return None\n",
    "\n",
    "    t = torch.tensor(log['t'], dtype=torch.float32, device=device).unsqueeze(1)\n",
    "    u = torch.tensor(log['u'], dtype=torch.float32, device=device).unsqueeze(1)\n",
    "    theta_meas = torch.tensor(log['theta'], dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "    # Normalize time to [-1, 1] for smoother training\n",
    "    t_min, t_max = t.min(), t.max()\n",
    "    t_norm = (2.0 * (t - t_min) / (t_max - t_min + 1e-9)) - 1.0\n",
    "    # IMPORTANT: PINN needs gradients w.r.t. time\n",
    "    t_norm = t_norm.clone().detach().requires_grad_(True)\n",
    "\n",
    "    model = PINNStateOfTime(hidden=64).to(device)\n",
    "    model.train()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        opt.zero_grad()\n",
    "        y = model(t_norm)  # [theta, omega]\n",
    "        theta = y[:, :1]\n",
    "        omega = y[:, 1:2]\n",
    "        dtheta_dt = torch.autograd.grad(theta, t_norm, grad_outputs=torch.ones_like(theta),\n",
    "                                        create_graph=True, retain_graph=True)[0]\n",
    "        domega_dt = torch.autograd.grad(omega, t_norm, grad_outputs=torch.ones_like(omega),\n",
    "                                        create_graph=True, retain_graph=True)[0]\n",
    "        dt_norm_dt = 2.0 / (t_max - t_min + 1e-9)\n",
    "        theta_t = dtheta_dt * dt_norm_dt\n",
    "        omega_t = domega_dt * dt_norm_dt\n",
    "\n",
    "        bhat = model.b_hat\n",
    "        r1 = theta_t - omega\n",
    "        r2 = m * (l ** 2) * omega_t + bhat * omega + m * g * l * torch.sin(theta) - u\n",
    "        loss_resid = (r1 ** 2).mean() + (r2 ** 2).mean()\n",
    "\n",
    "        loss_data = ((theta - theta_meas) ** 2).mean()\n",
    "        bc_theta = (theta[0] - theta_meas[0])**2\n",
    "        bc_omega = (omega[0] - 0.0)**2\n",
    "\n",
    "        if b_prior is not None:\n",
    "            loss_bprior = (bhat - float(b_prior))**2\n",
    "        else:\n",
    "            loss_bprior = torch.zeros_like(loss_resid)\n",
    "\n",
    "        if ep < warmup_epochs:\n",
    "            loss = data_weight * loss_data + 1e-2 * bc_theta + 1e-3 * bc_omega + b_prior_w * loss_bprior\n",
    "        else:\n",
    "            loss = loss_resid + data_weight * loss_data + 1e-2 * bc_theta + 1e-3 * bc_omega + b_prior_w * loss_bprior\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        if (ep + 1) % 200 == 0 or ep == 0:\n",
    "            print(f\"[PINN] epoch {ep+1:4d}  loss={loss.item():.4e}  resid={loss_resid.item():.4e}  data={loss_data.item():.4e}  b_hat={bhat.item():.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(t_norm)\n",
    "        theta_hat = y_hat[:, 0].cpu().numpy()\n",
    "        b_hat = float(model.b_hat.item())\n",
    "\n",
    "    artifact = PINNArtifact(hidden=64,\n",
    "                           state_dict=model.state_dict(),\n",
    "                           t_min=float(t_min.cpu().item() if hasattr(t_min, 'cpu') else t_min),\n",
    "                           t_max=float(t_max.cpu().item() if hasattr(t_max, 'cpu') else t_max),\n",
    "                           b_hat=b_hat)\n",
    "    return {\n",
    "        't': log['t'],\n",
    "        'theta_hat': theta_hat,\n",
    "        'b_hat': b_hat,\n",
    "        'loss_final': float(loss.item()),\n",
    "        'artifact': artifact\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b841faa1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Visualization helpers\n",
    "# -----------------------------\n",
    "\n",
    "def save_pendulum_animation(t: np.ndarray, theta: np.ndarray, out_prefix: str = \"animation/pendulum\",\n",
    "                            fps: int = 30, skip: int = 1, speed: float = 1.0, L: float = 1.0) -> None:\n",
    "    \"\"\"One clean function: save (t, theta) animation to both GIF and MP4.\n",
    "    - Creates parent folders of out_prefix if needed.\n",
    "    - Saves `<out_prefix>.gif` (Pillow) and `<out_prefix>.mp4` (FFmpeg) when possible.\n",
    "    - Does not show a window; just writes the files.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from matplotlib import animation as _anim\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    out_dir = os.path.dirname(out_prefix) or \".\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    x = L * np.sin(theta)\n",
    "    y = -L * np.cos(theta)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_title(os.path.basename(out_prefix).replace(\"_\", \" \"))\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(-1.2 * L, 1.2 * L)\n",
    "    ax.set_ylim(-1.2 * L, 1.2 * L)\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Upright goal\n",
    "    (goal_line,) = ax.plot([0, 0], [0, L], linestyle=':', linewidth=1)\n",
    "    (rod_line,) = ax.plot([0, x[0]], [0, y[0]], lw=3)\n",
    "    (bob_point,) = ax.plot([x[0]], [y[0]], 'o', ms=10)\n",
    "    time_text = ax.text(0.02, 0.95, '', transform=ax.transAxes)\n",
    "\n",
    "    def update(i):\n",
    "        j = min(i * skip, len(t) - 1)\n",
    "        rod_line.set_data([0, x[j]], [0, y[j]])\n",
    "        bob_point.set_data([x[j]], [y[j]])\n",
    "        time_text.set_text(f\"t = {t[j]:.2f} s\")\n",
    "        return rod_line, bob_point, time_text, goal_line\n",
    "\n",
    "    frames = int(math.ceil(len(t) / max(skip, 1)))\n",
    "    interval_ms = 1000.0 * (t[1] - t[0]) * max(skip, 1) / max(speed, 1e-6)\n",
    "    ani = FuncAnimation(fig, update, frames=frames, interval=interval_ms, blit=False, repeat=False)\n",
    "\n",
    "    # Save GIF\n",
    "    try:\n",
    "        writer_gif = _anim.PillowWriter(fps=fps)\n",
    "        ani.save(f\"{out_prefix}.gif\", writer=writer_gif)\n",
    "        print(f\"Saved → {out_prefix}.gif\")\n",
    "    except Exception as e:\n",
    "        print(f\"[save_pendulum_animation] GIF save failed: {e}\")\n",
    "\n",
    "    # Save MP4\n",
    "    try:\n",
    "        writer_mp4 = _anim.FFMpegWriter(fps=fps)\n",
    "        ani.save(f\"{out_prefix}.mp4\", writer=writer_mp4)\n",
    "        print(f\"Saved → {out_prefix}.mp4\")\n",
    "    except Exception as e:\n",
    "        print(f\"[save_pendulum_animation] MP4 save failed: {e}\")\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def animate_theta_series(t: np.ndarray, theta: np.ndarray, *, title: str = \"Pendulum Animation\",\n",
    "                         L: float = 1.0, realtime: bool = True, speed: float = 1.0, skip: int = 1,\n",
    "                         save_path: str | None = None, fps: int = 30, show: bool = True):\n",
    "    \"\"\"Standalone animation from any (t, theta) series.\n",
    "    Use this to animate either the plant or a learned model like the PINN.\n",
    "    \"\"\"\n",
    "    x = L * np.sin(theta)\n",
    "    y = -L * np.cos(theta)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_title(title)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(-1.2 * L, 1.2 * L)\n",
    "    ax.set_ylim(-1.2 * L, 1.2 * L)\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Upright goal marker\n",
    "    (goal_line,) = ax.plot([0, 0], [0, L], linestyle=':', linewidth=1)\n",
    "    (rod_line,) = ax.plot([0, x[0]], [0, y[0]], lw=3)\n",
    "    (bob_point,) = ax.plot([x[0]], [y[0]], 'o', ms=10)\n",
    "    time_text = ax.text(0.02, 0.95, '', transform=ax.transAxes)\n",
    "\n",
    "    def update(i):\n",
    "        j = i * skip\n",
    "        if j >= len(t):\n",
    "            j = len(t) - 1\n",
    "        rod_line.set_data([0, x[j]], [0, y[j]])\n",
    "        bob_point.set_data([x[j]], [y[j]])\n",
    "        time_text.set_text(f\"t = {t[j]:.2f} s\")\n",
    "        return rod_line, bob_point, time_text, goal_line\n",
    "\n",
    "    frames = int(math.ceil(len(t) / max(skip, 1)))\n",
    "    interval_ms = 1000.0 * (t[1] - t[0]) * max(skip, 1) / max(speed, 1e-6) if realtime else 60\n",
    "    ani = FuncAnimation(fig, update, frames=frames, interval=interval_ms, blit=False, repeat=False)\n",
    "\n",
    "    # Save if requested (gif/mp4 depending on extension and installed writers)\n",
    "    if save_path is not None:\n",
    "        try:\n",
    "            from matplotlib import animation as _anim\n",
    "            if save_path.lower().endswith('.gif'):\n",
    "                writer = _anim.PillowWriter(fps=fps)\n",
    "            else:\n",
    "                writer = _anim.FFMpegWriter(fps=fps)\n",
    "            ani.save(save_path, writer=writer)\n",
    "            print(f\"Saved animation → {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[animate_theta_series] Save failed: {e}\")\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return ani\n",
    "\n",
    "\n",
    "def plot_timeseries(log: Dict[str, np.ndarray], pinn_out: Dict[str, np.ndarray] | None = None):\n",
    "    t = log['t']\n",
    "    theta = log['theta']\n",
    "    theta_dot = log['theta_dot']\n",
    "    u = log['u']\n",
    "    setp = log['setpoint']\n",
    "\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(8, 8), sharex=True)\n",
    "    axs[0].plot(t, theta, label='θ (plant)')  # plot plant angle\n",
    "    if pinn_out is not None:\n",
    "        axs[0].plot(t, pinn_out['theta_hat'], '--', label='θ (PINN)')\n",
    "        axs[0].set_title(f\"Angle — PINN b_hat={pinn_out['b_hat']:.4f}\")\n",
    "    else:\n",
    "        axs[0].set_title(\"Angle\")\n",
    "    axs[0].plot(t, setp, ':', label='setpoint')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    axs[1].plot(t, theta_dot, label='θ̇')\n",
    "    axs[1].set_title(\"Angular rate\")\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    axs[2].plot(t, u, label='u (torque)')\n",
    "    axs[2].set_title(\"Control torque\")\n",
    "    axs[2].grid(True)\n",
    "    axs[2].set_xlabel(\"Time [s]\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def animate_pendulum(log: Dict[str, np.ndarray], skip: int = 2, realtime: bool = True, speed: float = 1.0):\n",
    "    t = log['t']\n",
    "    theta = log['theta']\n",
    "\n",
    "    # Simple rod from origin\n",
    "    L = 1.0\n",
    "    x = L * np.sin(theta)\n",
    "    y = -L * np.cos(theta)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(-1.2 * L, 1.2 * L)\n",
    "    ax.set_ylim(-1.2 * L, 1.2 * L)\n",
    "    ax.grid(True)\n",
    "\n",
    "    # goal reference (upright)\n",
    "    (goal_line,) = ax.plot([0, 0], [0, L], linestyle=':', linewidth=1)\n",
    "    (rod_line,) = ax.plot([0, x[0]], [0, y[0]], lw=3)\n",
    "    (bob_point,) = ax.plot([x[0]], [y[0]], 'o', ms=10)\n",
    "    time_text = ax.text(0.02, 0.95, '', transform=ax.transAxes)\n",
    "\n",
    "    def update(i):\n",
    "        j = i * skip\n",
    "        if j >= len(t):\n",
    "            j = len(t) - 1\n",
    "        rod_line.set_data([0, x[j]], [0, y[j]])\n",
    "        bob_point.set_data([x[j]], [y[j]])\n",
    "        return rod_line, bob_point\n",
    "\n",
    "    frames = int(math.ceil(len(t) / skip))\n",
    "    # Slow down/speed up using dt and skip for near real-time playback\n",
    "    interval_ms = 1000.0 * (t[1]-t[0]) * skip / max(speed, 1e-6) if realtime else 60\n",
    "    ani = FuncAnimation(fig, update, frames=frames, interval=interval_ms, blit=False, repeat=False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Convenience API (so you don't need access to internal vars)\n",
    "# -----------------------------\n",
    "\n",
    "def run_sim(T: float = 8.0, params: PendulumParams | None = None, pid_gains: tuple[float,float,float] = (15.0,2.0,3.0),\n",
    "            dt: float = 0.01, setpoint: float = math.pi, pre_kick: float | None = 1.5, kick_duration: float = 0.15,\n",
    "            theta0: float = 0.0, theta_dot0: float = 0.0) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Run the closed-loop plant and return the telemetry log.\"\"\"\n",
    "    if params is None:\n",
    "        params = PendulumParams()\n",
    "        params.b = 0.06  # default used in paper demo\n",
    "    plant = InvertedPendulumPlant(params)\n",
    "    pid = PID(*pid_gains, u_max=2.5, i_clamp=0.6)\n",
    "    twin = DigitalTwin(plant, pid, dt=dt)\n",
    "    return twin.run(T=T, theta0=theta0, theta_dot0=theta_dot0, setpoint=setpoint,\n",
    "                    pre_kick=pre_kick, kick_duration=kick_duration)\n",
    "\n",
    "\n",
    "def fit_pinn_from_log(log: Dict[str, np.ndarray], params: PendulumParams | None = None,\n",
    "                      **kwargs) -> Dict[str, np.ndarray] | None:\n",
    "    \"\"\"Train a PINN from a telemetry log and return {'t','theta_hat','b_hat',...}.\n",
    "    kwargs are forwarded to train_pinn (epochs, data_weight, etc.).\n",
    "    \"\"\"\n",
    "    if not TORCH_AVAILABLE:\n",
    "        print(\"PyTorch not available — skipping PINN training.\")\n",
    "        return None\n",
    "    if params is None:\n",
    "        params = PendulumParams()\n",
    "        params.b = 0.06\n",
    "    return train_pinn(log, m=params.m, l=params.l, g=params.g, **kwargs)\n",
    "\n",
    "\n",
    "def animate_plant_from_log(log: Dict[str, np.ndarray], **kwargs):\n",
    "    \"\"\"Animate the plant using the log.\"\"\"\n",
    "    title = kwargs.pop('title', \"Plant (truth)\")\n",
    "    animate_theta_series(log['t'], log['theta'], title=title, **kwargs)\n",
    "\n",
    "\n",
    "def animate_pinn_from_result(pinn_out: Dict[str, np.ndarray], **kwargs):\n",
    "    animate_theta_series(pinn_out['t'], pinn_out['theta_hat'],\n",
    "                         title=f\"PINN (b_hat={pinn_out['b_hat']:.3f})\", **kwargs)\n",
    "\n",
    "def animate_pinn_from_artifact(art: PINNArtifact, t: np.ndarray, **kwargs):\n",
    "    theta_hat = art.predict_theta(t)\n",
    "    title = kwargs.pop('title', f\"PINN (b_hat={art.b_hat:.3f})\")\n",
    "    animate_theta_series(t, theta_hat, title=title, **kwargs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9347a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Demo / main\n",
    "# -----------------------------\n",
    "\n",
    "def main_demo_artifact(T: float = 8.0, epochs: int = 1200, save_path: str = \"pinn_artifact.pt\",\n",
    "                        data_weight: float = 5e-2, animate: bool = True):\n",
    "    \"\"\"One-liner classroom demo: run plant, train PINN once, save artifact, plot, animate.\n",
    "\n",
    "    Usage (from shell):\n",
    "        python -c \"import inverted_pendulum_dt as ip; ip.main_demo_artifact()\"\n",
    "    or inside a notebook / REPL:\n",
    "        import inverted_pendulum_dt as ip\n",
    "        ip.main_demo_artifact()\n",
    "    \"\"\"\n",
    "    # 1) Run the plant + PID to get telemetry\n",
    "    log = run_sim(T=T)\n",
    "\n",
    "    # 2) Train the PINN briefly and get the reusable artifact\n",
    "    pinn_out = fit_pinn_from_log(log, epochs=epochs, data_weight=data_weight)\n",
    "    if pinn_out is None:\n",
    "        print(\"[main_demo_artifact] PyTorch not available; skipping PINN training.\")\n",
    "        plot_timeseries(log, None)\n",
    "        if animate:\n",
    "            save_pendulum_animation(log['t'], log['theta'], out_prefix=\"animations/plant\", fps=30, skip=1, speed=0.7)\n",
    "        return\n",
    "\n",
    "    art = pinn_out['artifact']\n",
    "\n",
    "    # 3) Save the artifact for reuse without retraining\n",
    "    if TORCH_AVAILABLE:\n",
    "        torch.save({\n",
    "            'hidden': art.hidden,\n",
    "            'state_dict': art.state_dict,\n",
    "            't_min': art.t_min,\n",
    "            't_max': art.t_max,\n",
    "            'b_hat': art.b_hat,\n",
    "        }, save_path)\n",
    "        print(f\"Saved PINN artifact → {save_path}  (b_hat={art.b_hat:.4f})\")\n",
    "\n",
    "    # 4) Plots + save animations (plant vs PINN)\n",
    "    plot_timeseries(log, pinn_out)\n",
    "    if animate:\n",
    "        save_pendulum_animation(log['t'], log['theta'], out_prefix=\"animations/plant_RK\", fps=30, skip=1, speed=0.7)\n",
    "        theta_hat = art.predict_theta(log['t'])\n",
    "        save_pendulum_animation(log['t'], theta_hat, out_prefix=\"animations/pinn_RK\", fps=30, skip=1, speed=0.7)\n",
    "        animate_pinn_from_artifact(art, log['t'], speed=0.7, skip=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23821910",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # True plant params (you can change these for demos)\n",
    "    params = PendulumParams(m=0.5, l=0.5, b=0.06, g=9.81)\n",
    "\n",
    "    plant = InvertedPendulumPlant(params)\n",
    "\n",
    "    # A reasonable starting PID for a gentle swing-up + hold\n",
    "    # Increase Kp/Kd for tighter attitude control; add small Ki to remove bias\n",
    "    pid = PID(kp=15.0, ki=2.0, kd=3.0, u_max=2.5, i_clamp=0.6)\n",
    "\n",
    "    dt = 0.01\n",
    "    twin = DigitalTwin(plant, pid, dt=dt)\n",
    "\n",
    "    # You can optionally give a tiny initial kick to help swing-up\n",
    "    log = twin.run(T=8.0, theta0=0.0, theta_dot0=0.0, setpoint=math.pi, pre_kick=1.5, kick_duration=0.15)\n",
    "\n",
    "    # Visualize time series\n",
    "    pinn_out = None\n",
    "\n",
    "    # Train PINN (optional — set to False to skip in class)\n",
    "    DO_PINN = True and TORCH_AVAILABLE\n",
    "    if DO_PINN:\n",
    "        pinn_out = train_pinn(log, m=params.m, l=params.l, g=params.g,\n",
    "                              epochs=2500, lr=1e-3, data_weight=2e-2,\n",
    "                              b_prior=params.b, b_prior_w=5e-3,\n",
    "                              device='cpu')\n",
    "\n",
    "    plot_timeseries(log, pinn_out)\n",
    "    # Slower, larger animation with goal reference and time text\n",
    "    animate_pendulum(log, skip=2, realtime=True, speed=0.7)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b15a045",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Plant\n",
    "log = run_sim(T=8.0)\n",
    "save_pendulum_animation(log['t'], log['theta'], out_prefix=\"animations/plant\", fps=30, skip=1, speed=0.7)\n",
    "\n",
    "# PINN (train once, then reuse)\n",
    "pinn_out = fit_pinn_from_log(log, epochs=1200, data_weight=5e-2)\n",
    "art = pinn_out['artifact']\n",
    "theta_hat = art.predict_theta(log['t'])\n",
    "save_pendulum_animation(log['t'], theta_hat, out_prefix=\"animations/pinn\", fps=30, skip=1, speed=0.7)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
